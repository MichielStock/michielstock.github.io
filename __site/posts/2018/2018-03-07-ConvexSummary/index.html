<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
     <link rel="stylesheet" href="/libs/katex/katex.min.css">
     
    
    <link rel="stylesheet" href="/css/franklin.css">
<link rel="stylesheet" href="/css/tufte.css">
<link rel="stylesheet" href="/css/latex.css">
<link rel="stylesheet" href="/css/adjust.css"> <!-- sheet to overwrite some clashing styles -->
<link rel="icon" href="/assets/favicon.png">

     <title>Lessons from convex optimization</title>  
</head>

<script type="application/javascript">
	var doNotTrack = false;
	if (!doNotTrack) {
		window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
		ga('create', 'UA-110926897-1', 'auto');
		ga('send', 'pageview');
	}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

<body>
<div id="layout">
  <div id="menu">
    <ul>
      <li><a href="/">Home</a></li>
      <li><a href="/CV/">CV</a></li>
      <li><a href="/research/">Research</a></li>
      <li><a href="/blog/">Blog</a></li>
    </ul>
  </div>
  <div id="main">



<!-- Content appended here -->
<div class="franklin-content">
<h1 id="lessons_from_convex_optimization"><a href="#lessons_from_convex_optimization" class="header-anchor">Lessons from convex optimization</a></h1>
<p>In the last four weeks, I taught about convex optimization to my bioinformatics students. Since this topic is of general interest to those working with data and models, I will try to summarize the main points that the &#39;casual optimizer&#39; should know. For a much more comprehensive overview, I refer to the excellent textbook of Boyd and Vandenberghe referenced below.</p>
<h2 id="convex_functions"><a href="#convex_functions" class="header-anchor">Convex functions</a></h2>
<p>A <em>convex set</em> \(\mathcal{C}\) is a set for which every element on a line segment connecting two points \(\mathbf{x},\mathbf{x}'\in\mathcal{C}\) is also in this set.</p>
<p>A <em>convect function</em> \(f\) is a function for which the input domain is convex and for which it holds that</p>
\[
f(\theta\mathbf{x}+(1-\theta)\mathbf{x}')\leq \theta f(\mathbf{x})+(1-\theta)f(\mathbf{x}')\quad \forall \theta\in[0,1]\,,
\]
<p>meaning that any line segment connecting two points on this curve lies above the curve.</p>
<p><img src="/images/2018_convex/convex_function_illustration.png" alt="A convex function." /></p>
<p>If the function is differentiable it also holds that the first-order Taylor approximation lies below the curve:</p>
\[
f(\mathbf{x})\geq f(\mathbf{x}')+\nabla f(\mathbf{x}')^\top(\mathbf{x}-\mathbf{x}')\,.
\]
<p>Convex functions are nice because when it has a minimum, this minimum is a global minimum. Such functions frequently arise in statistics and machine learning. Many machine learning methods, such as the support vector machine, are specifically posed as convex optimization problems.</p>
<h2 id="quadratic_function"><a href="#quadratic_function" class="header-anchor">Quadratic function</a></h2>
<p>An important special case of convex functions are <em>quadratic minimization problems</em>:</p>
\[
\min_\mathbf{x}\,\frac{1}{2}\mathbf{x}^\top P \mathbf{x} + \mathbf{q}^\top\mathbf{x} + r\,,
\]
<p>with \(P\) symmetric and positive-definite &#40;i.e. all eigenvectors are greater than zero&#41;.</p>
<p>These have a closed-form solution:</p>
\[
\mathbf{x}^\star = -P^{-1}\mathbf{q}\,.
\]
<p>Quadratic systems are important for least-squares-based learning and in certain graph problems. From a theoretical point of view, they are important because convex problems can be closely approximated by quadratic functions near their minimum, the region we are interested in&#33;</p>
<h2 id="general_descent_algorithms"><a href="#general_descent_algorithms" class="header-anchor">General descent algorithms</a></h2>
<p>For general convex optimization problems, one usually uses <em>descent algorithms</em>. The pseudocode of the general algorithm is given below.</p>
<blockquote>
<p><strong>given</strong> a starting point \(\mathbf{x}\)<br/> <strong>repeat</strong></p>
<blockquote>
<ol>
<li><p>Determine descent direction \(\Delta \mathbf{x}\)<br/></p>
</li>
<li><p><em>Line search</em>. Choose \(t>0\).<br/></p>
</li>
<li><p><em>Update</em>. \(\mathbf{x}:=\mathbf{x} + t \Delta \mathbf{x}\).<br/></p>
</li>
</ol>
</blockquote>
<p><strong>until</strong> stopping criterion is reached.</p>
<p><strong>Output</strong>: \(\mathbf{x}\)</p>
</blockquote>
<p>Descent algorithms differ by their <em>descent direction</em>, method for choosing the <em>step size</em> and the <em>convergence criterion</em>  &#40;often based on the norm of the gradient&#41;.</p>
<p>Proper descent methods have that</p>
\[
(\Delta \mathbf{x})^\top \nabla f(\mathbf{x})\leq 0\,.
\]
<p><img src="/images/2018_convex/descent_step.png" alt="Descent and ascent step." /></p>
<h2 id="gradient_descent"><a href="#gradient_descent" class="header-anchor">Gradient descent</a></h2>
<p>A straightforward choice for the step size is the negative gradient:</p>
\[
\Delta \mathbf{x} = -\nabla f(\mathbf{x})\,.
\]
<p>Though this seems to make sense, in practice the convergence is rather poor. If \(f\) is strongly convex &#40;constants \(m\) and \(M\) exist such that \(mI\prec \nabla^2 f(\mathbf{x})\prec MI\)&#41;, it holds that \(f(\mathbf{x}^{(k)}) - p^*\leq \varepsilon\) after at most</p>
\[
\frac{\log((f(\mathbf{x}^{(0)}) - p^*)/\varepsilon)}{\log(1/c)}
\]
<p>iterations, where \(c =1-\frac{m}{M}<1\).</p>
<p>We conclude:</p>
<ul>
<li><p>The number of steps needed for a given quality is proportional to the logarithm of the initial error.</p>
</li>
<li><p>To increase the accuracy with an order of magnitude, only a few more steps are needed.</p>
</li>
<li><p>Convergence is again determined by the <em>condition number</em> \(M/m\). Note that for large condition numbers: \(\log(1/c)=-\log(1-\frac{m}{M})\approx m/M\), so the number of required iterations increases linearly with increasing \(M/m\).</p>
</li>
</ul>
<p>So the convergence is mainly determined by the shape of the function. See below for the example of the convergence on a quadratic and non-quadratic function.</p>
<p><img src="/images/2018_convex/gradient_descent.png" alt="Path of gradient descent on the quadratic and non-quadratic functions." /> <img src="/images/2018_convex/convergence_gd.png" alt="Convergence of gradient descent on the quadratic and non-quadratic functions." /></p>
<p>Note that even for such simple two-dimensional problems, pure gradient descent takes a long time to converge.</p>
<h2 id="newtons_method"><a href="#newtons_method" class="header-anchor">Newton&#39;s method</a></h2>
<p>The main idea of <strong>Newton&#39;s method</strong> is approximating a function with a second-order Taylor approximation \(\hat{f}\) of \(f\) at \(\mathbf{x}\):</p>
\[
f(\mathbf{x}+\mathbf{v})\approx\hat{f}(\mathbf{x}+\mathbf{v}) = f(\mathbf{x}) + \nabla f(\mathbf{x})^\top \mathbf{v} + \frac{1}{2} \mathbf{v}^\top \nabla^2 f(\mathbf{x}) \mathbf{v}\,
\]
<p>which is a convex quadratic function of \(\mathbf{v}\). The <em>Newton step</em> is the step that minimizes this approximation in \(\mathbf{v}\). The step is hence given by</p>
\[
\Delta \mathbf{x} = -(\nabla^2 f(\mathbf{x}))\nabla f(\mathbf{x})\,.
\]
<p>Using the newton step in the general descent algorithm generally leads to a very fast convergence, especially when close to the minimum. Newton&#39;s method is much more robust to bad condition numbers and is <em>affine invariant</em>, scaling, translating or rotating the input domain does not influence its performance.</p>
<h2 id="linear_equality_constraints"><a href="#linear_equality_constraints" class="header-anchor">Linear equality constraints</a></h2>
<p>Sometimes we want to minimize a function with respect to a <em>linear equality constraint</em>:</p>
\[
\min_\mathbf{x} f(\mathbf{x})
\]
\[
\text{subject to } A\mathbf{x}=\mathbf{b}
\]
<p>where \(f : \mathbb{R}^n \rightarrow \mathbb{R}\) is convex and twice continuously differentiable and \(A\in \mathbb{R}^{p\times n}\) with a rank \(p < n\).</p>
<p>A special Newton step which respects these constraints can be obtained by solving the following system:</p>
\[
\begin{bmatrix}
 \nabla^2 f(\mathbf{x})&  A^\top \\
A & 0 \\
     \end{bmatrix}
     \begin{bmatrix}
\Delta \mathbf{x}_\text{nt}\\
\mathbf{w}
     \end{bmatrix}
     =
     -\begin{bmatrix}
\nabla f(\mathbf{x}) \\
A\mathbf{x}-\mathbf{b}
     \end{bmatrix}\,.
\]
<p>Note that:</p>
<ul>
<li><p>If the starting point \(\mathbf{x}^{(0)}\) is chosen such that \(A\mathbf{x}^{(0)}=\mathbf{b}\), the residual term vanishes and steps will remain in the feasible region. This is the <strong>feasible start Newton method</strong>.</p>
</li>
<li><p>If we choose an arbitrary \(\mathbf{x}^{(0)}\in\)<strong>dom</strong> \(f\), not satisfying the constraints, this is the <strong>infeasible start Newton method</strong>. It will usually converge rapidly to the feasible region &#40;check the final solution&#33;&#41;.</p>
</li>
</ul>
<h2 id="inequality_constraints"><a href="#inequality_constraints" class="header-anchor">Inequality constraints</a></h2>
<p>Dealing with inequality constrains is more complex. In general, we want to solve</p>
\[
\min_\mathbf{x}  f_0(\mathbf{x})
\]
\[
\text{subject to } f_i(\mathbf{x}) \leq 0, \quad i=1,\ldots,m
\]
<p>where \(f_0,\ldots,f_m\ :\ \mathbb{R}^n \rightarrow \mathbb{R}\) are convex and twice continuously differentiable.</p>
<p>A trick is reformulating the problem using soft constraints in the objective function:</p>
\[
\min_\mathbf{x}  tf_0(\mathbf{x})-\sum_{i=1}^m\log(-f_i(\mathbf{x}))\,,
\]
<p>where we used the <em>logarithmic barrier</em> to approximate the inequality constraints. The parameter \(t\) determines the sharpness of the approximation, as illustrated below.</p>
<p><img src="/images/2018_convex/log_bar.png" alt="Larger values of \(t\) result in a better approximation of" /></p>
<p>High values of \(t\) result in a very good approximation but are hard to optimize because they are ill-conditioned. <em>Interior point methods</em> start with a low value of \(t\) to obtain an initial solution and iteratively use the previous solution as a starting point for the soft-constrained optimization problem with increased \(t\).</p>
<h2 id="references"><a href="#references" class="header-anchor">References</a></h2>
<ul>
<li><p>Boyd, S. and Vandenberghe, L., &#39;<em><a href="https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf">Convex Optimization</a></em>&#39;. Cambridge University Press &#40;2004&#41;</p>
</li>
<li><p>Bishop, C., <em>Pattern Recognition and Machine Learning</em>. Springer &#40;2006&#41;</p>
</li>
</ul>
<div class="page-foot">
  <div class="copyright">
    &copy; Michiel Stock. Last modified: February 20, 2021. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
  </div>
</div>
</div><!-- CONTENT ENDS HERE -->
        </div> <!-- end of id=main -->
    </div> <!-- end of id=layout -->
    
        <script src="/libs/katex/katex.min.js"></script>
<script src="/libs/katex/auto-render.min.js"></script>
<script>renderMathInElement(document.body)</script>

    
    
  </body>
</html>
