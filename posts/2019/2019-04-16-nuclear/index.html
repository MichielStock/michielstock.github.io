<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/katex/katex.min.css"> <link rel=stylesheet  href="/libs/highlight/github.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/tufte.css"> <link rel=stylesheet  href="/css/latex.css"> <link rel=stylesheet  href="/css/adjust.css"> <link rel=icon  href="/assets/favicon.png"> <title>On recovering matrices</title> <script type="application/javascript"> var doNotTrack = false; if (!doNotTrack) { window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date; ga('create', 'UA-110926897-1', 'auto'); ga('send', 'pageview'); } </script> <script async src='https://www.google-analytics.com/analytics.js'></script> <div id=layout > <div id=menu > <ul> <li><a href="/">Home</a> <li><a href="/CV/">CV</a> <li><a href="/research/">Research</a> <li><a href="/teaching/">Teaching</a> <li><a href="/blog/">Blog</a> </ul> </div> <div id=main > <div class=franklin-content > <h1 id=on_recovering_matrices ><a href="#on_recovering_matrices" class=header-anchor >On recovering matrices</a></h1> <p><img src="/images/2019_nuclear/brandy-turner-517339-unsplash.jpg" alt="Photo by brandy turner on Unsplash." /></p> <p>Most of my research is focused on predicting matrix-valued data &#40;&#39;pairwise learning&#39;&#41;. This works by either having features of the rows and columns or by exploiting some kind of structure in the matrix. One particularly appealing type of structure is that a matrix <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> is low rank, i.e.</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mi>X</mi><mo>≈</mo><mi>U</mi><msup><mi>V</mi><mo>⊺</mo></msup><mtext> </mtext><mo separator=true >,</mo></mrow><annotation encoding="application/x-tex"> X \approx UV^\intercal\,, </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >≈</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.9088320000000001em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class=mord ><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.714392em;"><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin amsrm mtight">⊺</span></span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mpunct >,</span></span></span></span></span> <p>where both <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi></mrow><annotation encoding="application/x-tex">U</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span></span></span></span> and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span> are &#39;long&#39;: they have many rows but few columns. Many large matrices can be modelled as such, since it is assumed that there are only a couple of hidden variables that explain the data. This principle is widely used in unsupervised learning &#40;factorization methods such as PCA and the like&#41; and can be exploited to, for example, find the <a href="https://link.springer.com/article/10.1007/s10618-016-0456-z">topmost relevant items efficiently</a>.</p> <p>One way to find low-rank matrices is by adding the nuclear norm as a matrix regularizer. This could recover a low-rank matrix. Only very recently it finally clicked in my mind how this works. This post is a small technical note on how to use empirical risk minimization to recover matrices, with an emphasis low-rank and positive semi-definite ones. As an illustration, I will show that with some straightforward code, we can obtain a better estimate of a correlation matrix. The Jupyter notebook of this post can be found on my <a href="https://github.com/MichielStock/Teaching/blob/master/Nuclearnorm/nuclear_norm.ipynb">Github</a>.</p> <h2 id=recovering_matrices ><a href="#recovering_matrices" class=header-anchor >Recovering matrices</a></h2> <p>Suppose we have matrix <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span> of observations, for example user-item ratings, interaction values between drugs and protein targets, or the adjacency matrix of a food web. If we expect that the values of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span> are corrupted or if <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span> is incomplete, we need to re-estimate <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span> by a hopefully better matrix <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>. In machine learning, such problems are approached by solving an <em>empirical risk minimization problem</em> &#40;ERMP&#41;:</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><munder><mo><mi>min</mi><mo>⁡</mo></mo><mi>X</mi></munder><mi>l</mi><mo stretchy=false >(</mo><mi>Y</mi><mo separator=true >,</mo><mi>X</mi><mo stretchy=false >)</mo><mo>+</mo><mi>λ</mi><mo>⋅</mo><mi>h</mi><mo stretchy=false >(</mo><mi>X</mi><mo stretchy=false >)</mo><mtext> </mtext><mi mathvariant=normal >.</mi></mrow><annotation encoding="application/x-tex"> \min_X l(Y, X) +\lambda \cdot h(X)\,. </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.4943309999999999em;vertical-align:-0.744331em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.66786em;"><span style="top:-2.355669em;margin-left:0em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span></span></span><span style="top:-3em;"><span class=pstrut  style="height:3em;"></span><span><span class=mop >min</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.744331em;"><span></span></span></span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">λ</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >⋅</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">h</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord >.</span></span></span></span></span> <p>This optimization problem has typically three parts:</p> <ul> <li><p>a <em>loss function</em> <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mo stretchy=false >(</mo><mo>⋅</mo><mo separator=true >,</mo><mo>⋅</mo><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">l(\cdot, \cdot)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class=mopen >(</span><span class=mord >⋅</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord >⋅</span><span class=mclose >)</span></span></span></span> which quantifies how well the matrix <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> approximates our observed matrix <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span>;</p> <li><p>a <em>regularization function</em> <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mo stretchy=false >(</mo><mo>⋅</mo><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">h(\cdot)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">h</span><span class=mopen >(</span><span class=mord >⋅</span><span class=mclose >)</span></span></span></span>, which we can use to impose some structure on the matrix <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>;</p> <li><p>a <em>regularization parameter</em> <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">λ</span></span></span></span>, a dial to adjust the relative trade-off between the two terms above.</p> </ul> <p>For the loss function, there are plenty of options, depending on the nature of the data &#40;regression, classification, many outliers...&#41;. We will just focus on the vanilla squared loss:</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mi>l</mi><mo stretchy=false >(</mo><mi>Y</mi><mo separator=true >,</mo><mi>X</mi><mo stretchy=false >)</mo><mo>=</mo><munder><mo>∑</mo><mrow><mi>i</mi><mo separator=true >,</mo><mi>j</mi></mrow></munder><mo stretchy=false >(</mo><msub><mi>Y</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>−</mo><msub><mi>X</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msup><mo stretchy=false >)</mo><mn>2</mn></msup><mtext> </mtext><mo separator=true >,</mo></mrow><annotation encoding="application/x-tex"> l(Y, X) = \sum_{i,j}(Y_{ij}-X_{ij})^2\,, </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:2.463782em;vertical-align:-1.413777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.050005em;"><span style="top:-1.8723309999999997em;margin-left:0em;"><span class=pstrut  style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.0500049999999996em;"><span class=pstrut  style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:1.413777em;"><span></span></span></span></span></span><span class=mopen >(</span><span class=mord ><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.286108em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >−</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:1.150216em;vertical-align:-0.286108em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.286108em;"><span></span></span></span></span></span></span><span class=mclose ><span class=mclose >)</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mpunct >,</span></span></span></span></span> <p>which is most appropriate if the elements of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span> are real-valued and meausurement errors are close to normally distributed. Note that if not all the values of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span> are observed, we can trivially deal with this by just taking the sum only over the values that are sampled.</p> <p>If we only minimize a loss, we will just obtain a matrix <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> with exactly the same content as <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span>, not particularly exciting&#33; The magic of the regularizer is that it will impose some structure on the learnt matrix <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>. The most basic assumption we can make is that the values of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> should not be &#39;too large&#39;, which can be enforced by <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal">L</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>: regularization:</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><msub><mi>h</mi><msub><mi>L</mi><mn>2</mn></msub></msub><mo stretchy=false >(</mo><mi>X</mi><mo stretchy=false >)</mo><mo>=</mo><munder><mo>∑</mo><mrow><mi>i</mi><mo separator=true >,</mo><mi>j</mi></mrow></munder><msubsup><mi>X</mi><mrow><mi>i</mi><mi>j</mi></mrow><mn>2</mn></msubsup><mtext> </mtext><mi mathvariant=normal >.</mi></mrow><annotation encoding="application/x-tex"> h_{L_2}(X) = \sum_{i,j} X_{ij}^2\,. </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.0001em;vertical-align:-0.2501em;"></span><span class=mord ><span class="mord mathnormal">h</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2501em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:2.463782em;vertical-align:-1.413777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.050005em;"><span style="top:-1.8723309999999997em;margin-left:0em;"><span class=pstrut  style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.0500049999999996em;"><span class=pstrut  style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:1.413777em;"><span></span></span></span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.864108em;"><span style="top:-2.4530000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.383108em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord >.</span></span></span></span></span> <p>The <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal">L</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> norm ensures that no value in <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> can grow too large, as the penalty is proportional to the squared value. The nice thing about this, if that in conjunction with the squared loss, the empirical risk minimization problem yields a closed-form solution.</p> <p>A popular alternative to <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal">L</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> regularization is by using <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">L_1</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal">L</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>-norm instead:</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><msub><mi>h</mi><msub><mi>L</mi><mn>1</mn></msub></msub><mo stretchy=false >(</mo><mi>X</mi><mo stretchy=false >)</mo><mo>=</mo><munder><mo>∑</mo><mrow><mi>i</mi><mo separator=true >,</mo><mi>j</mi></mrow></munder><mi mathvariant=normal >∣</mi><msub><mi>X</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi mathvariant=normal >∣</mi><mtext> </mtext><mi mathvariant=normal >.</mi></mrow><annotation encoding="application/x-tex"> h_{L_1}(X) = \sum_{i,j} |X_{ij}|\,. </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.0001em;vertical-align:-0.2501em;"></span><span class=mord ><span class="mord mathnormal">h</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2501em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:2.463782em;vertical-align:-1.413777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.050005em;"><span style="top:-1.8723309999999997em;margin-left:0em;"><span class=pstrut  style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.0500049999999996em;"><span class=pstrut  style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:1.413777em;"><span></span></span></span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord >∣</span><span class=mord ><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.286108em;"><span></span></span></span></span></span></span><span class=mord >∣</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord >.</span></span></span></span></span> <p>The <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">L_1</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal">L</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> norm enforces <em>sparsity</em>: many of the values in <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> will be driven to zero. Additionally, the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">L_1</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal">L</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, regulalizer, in contrast to <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal">L</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, is also more tolerant to having some larger values in <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> &#40;linear vs. quadratic penalty&#41;.</p> <p>What if, rather than having some demands on the individual values of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>, we want this matrix to be &#39;simple&#39; in a more global way? One way how <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> can be simple, is by searching for an <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> with a low rank, i.e. one that can be represented by a few dimensions. Is there a simple way to guide <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> towards having a low rank? Yes&#33; This can be done by considering the nuclear norm:</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mi mathvariant=normal >∣</mi><mi mathvariant=normal >∣</mi><mi>X</mi><mi mathvariant=normal >∣</mi><msub><mi mathvariant=normal >∣</mi><mo>⋆</mo></msub><mo>=</mo><msqrt><mrow><mtext>tr</mtext><mo stretchy=false >(</mo><msup><mi>X</mi><mo>⊺</mo></msup><mi>X</mi><mo stretchy=false >)</mo></mrow></msqrt><mtext> </mtext><mo separator=true >,</mo></mrow><annotation encoding="application/x-tex"> ||X||_\star = \sqrt{\text{tr}(X^\intercal X)}\,, </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord >∣</span><span class=mord >∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class=mord >∣</span><span class=mord ><span class=mord >∣</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.175696em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">⋆</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1.24em;vertical-align:-0.25612499999999994em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.983875em;"><span class=svg-align  style="top:-3.2em;"><span class=pstrut  style="height:3.2em;"></span><span class=mord  style="padding-left:1em;"><span class="mord text"><span class=mord >tr</span></span><span class=mopen >(</span><span class=mord ><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.590392em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin amsrm mtight">⊺</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class=mclose >)</span></span></span><span style="top:-2.9438750000000002em;"><span class=pstrut  style="height:3.2em;"></span><span class=hide-tail  style="min-width:1.02em;height:1.28em;"><svg width='400em' height='1.28em' viewBox='0 0 400000 1296' preserveAspectRatio='xMinYMin slice'><path d='M263,681c0.7,0,18,39.7,52,119 c34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120 c340,-704.7,510.7,-1060.3,512,-1067 l0 -0 c4.7,-7.3,11,-11,19,-11 H40000v40H1012.3 s-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232 c-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1 s-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26 c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60z M1001 80h400000v40h-400000z'/></svg></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.25612499999999994em;"><span></span></span></span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mpunct >,</span></span></span></span></span> <p>which leads to a regularizer:</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><msub><mi>h</mi><mtext>nucl</mtext></msub><mo stretchy=false >(</mo><mi>X</mi><mo stretchy=false >)</mo><mo>=</mo><mtext>tr</mtext><mo stretchy=false >(</mo><msup><mi>X</mi><mo>⊺</mo></msup><mi>X</mi><mo stretchy=false >)</mo><mtext> </mtext><mi mathvariant=normal >.</mi></mrow><annotation encoding="application/x-tex"> h_\text{nucl}(X) = \text{tr}(X^\intercal X)\,. </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathnormal">h</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">nucl</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class=mord >tr</span></span><span class=mopen >(</span><span class=mord ><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.714392em;"><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin amsrm mtight">⊺</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord >.</span></span></span></span></span> <p>So the trace &#40;taking the sum of the diagonal values of a matrix&#41; apparently holds the key to finding low-rank matrices. The reason is quite an interesting exercise in linear algebra. Note that the <a href="https://en.wikipedia.org/wiki/Singular_value_decomposition">singular value decompostion</a> of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> is written as:</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mi>X</mi><mo>=</mo><munder><mo>∑</mo><mi>k</mi></munder><msub><mi>σ</mi><mi>k</mi></msub><msub><mi mathvariant=bold >u</mi><mi>k</mi></msub><msubsup><mi mathvariant=bold >v</mi><mi>k</mi><mo>⊺</mo></msubsup><mtext> </mtext><mo separator=true >,</mo></mrow><annotation encoding="application/x-tex"> X = \sum_k\sigma_k\mathbf{u}_k\mathbf{v}^\intercal_k\,, </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:2.3521180000000004em;vertical-align:-1.3021129999999999em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.0500050000000005em;"><span style="top:-1.847887em;margin-left:0em;"><span class=pstrut  style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.050005em;"><span class=pstrut  style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:1.3021129999999999em;"><span></span></span></span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mord ><span class=mord ><span class="mord mathbf">u</span></span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mord ><span class=mord ><span class="mord mathbf" style="margin-right:0.01597em;">v</span></span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.7822999999999999em;"><span style="top:-2.3986920000000005em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.180908em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin amsrm mtight">⊺</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.3013079999999999em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mpunct >,</span></span></span></span></span> <p>with <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant=bold >u</mi><mn>1</mn></msub><mo separator=true >,</mo><msub><mi mathvariant=bold >u</mi><mn>2</mn></msub><mo separator=true >,</mo><mo>…</mo></mrow><annotation encoding="application/x-tex">\mathbf{u}_1, \mathbf{u}_2,\ldots</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.63888em;vertical-align:-0.19444em;"></span><span class=mord ><span class=mord ><span class="mord mathbf">u</span></span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord ><span class=mord ><span class="mord mathbf">u</span></span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=minner >…</span></span></span></span> and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant=bold >v</mi><mn>1</mn></msub><mo separator=true >,</mo><msub><mi mathvariant=bold >v</mi><mn>2</mn></msub><mo separator=true >,</mo><mo>…</mo></mrow><annotation encoding="application/x-tex">\mathbf{v}_1, \mathbf{v}_2,\ldots</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.63888em;vertical-align:-0.19444em;"></span><span class=mord ><span class=mord ><span class="mord mathbf" style="margin-right:0.01597em;">v</span></span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord ><span class=mord ><span class="mord mathbf" style="margin-right:0.01597em;">v</span></span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=minner >…</span></span></span></span> two sets of orthonormal eigenvectors and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>σ</mi><mn>1</mn></msub><mo separator=true >,</mo><msub><mi>σ</mi><mn>2</mn></msub><mo separator=true >,</mo><mo>…</mo></mrow><annotation encoding="application/x-tex">\sigma_1, \sigma_2,\ldots</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=minner >…</span></span></span></span> the eigenvalues of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>X</mi><mo>⊺</mo></msup><mi>X</mi></mrow><annotation encoding="application/x-tex">X^\intercal X</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin amsrm mtight">⊺</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>. If <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> is low rank, this means that many of these eigenvalues are zero. Note that these eigenvalues are all non-negative reals if <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> is a real-valued matrix. The trace of a matrix is equal to the sum of its eigenvalues, hence we can write</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mtext>tr</mtext><mo stretchy=false >(</mo><msup><mi>X</mi><mo>⊺</mo></msup><mi>X</mi><mo stretchy=false >)</mo><mo>=</mo><munder><mo>∑</mo><mi>k</mi></munder><msub><mi>σ</mi><mi>k</mi></msub><mo>=</mo><munder><mo>∑</mo><mi>k</mi></munder><mi mathvariant=normal >∣</mi><msub><mi>σ</mi><mi>k</mi></msub><mi mathvariant=normal >∣</mi><mtext> </mtext><mi mathvariant=normal >.</mi></mrow><annotation encoding="application/x-tex"> \text{tr}(X^\intercal X) = \sum_k \sigma_k = \sum_k |\sigma_k|\,. </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class=mord >tr</span></span><span class=mopen >(</span><span class=mord ><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.714392em;"><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin amsrm mtight">⊺</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:2.3521180000000004em;vertical-align:-1.3021129999999999em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.0500050000000005em;"><span style="top:-1.847887em;margin-left:0em;"><span class=pstrut  style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.050005em;"><span class=pstrut  style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:1.3021129999999999em;"><span></span></span></span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:2.3521180000000004em;vertical-align:-1.3021129999999999em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.0500050000000005em;"><span style="top:-1.847887em;margin-left:0em;"><span class=pstrut  style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.050005em;"><span class=pstrut  style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:1.3021129999999999em;"><span></span></span></span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord >∣</span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mord >∣</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord >.</span></span></span></span></span> <p>This means that the trace will place an <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal">L</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> regularization on the eigenvalues. Large values of the regularization parameter <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">λ</span></span></span></span> will drive many of the eigenvalues to zero, ensuring that <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> will be low rank &#40;<sup id="fnref:UV"><a href="#fndef:UV" class=fnref >[1]</a></sup>&#41;.</p> <h2 id=illustration_approximating_a_covariance_matrix ><a href="#illustration_approximating_a_covariance_matrix" class=header-anchor >Illustration: approximating a covariance matrix</a></h2> <p>Let us illustrate this on a related problem: re-estimating a covariance matrix &#40;<sup id="fnref:kernel"><a href="#fndef:kernel" class=fnref >[2]</a></sup>&#41;. Similar to the ERMP of above, we have a covariance matrix <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant=normal >Σ</mi></mrow><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class=mord >Σ</span></span></span></span> which we want to approximate by a matrix <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> &#40;for example because <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant=normal >Σ</mi></mrow><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class=mord >Σ</span></span></span></span> is subjected to high variance during estimation&#41;. The problem becomes:</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><munder><mo><mi>min</mi><mo>⁡</mo></mo><mrow><mi>S</mi><mo>⪰</mo><mn>0</mn></mrow></munder><mi>l</mi><mo stretchy=false >(</mo><mi mathvariant=normal >Σ</mi><mo separator=true >,</mo><mi>S</mi><mo stretchy=false >)</mo><mo>+</mo><mi>λ</mi><mo>⋅</mo><mi>h</mi><mo stretchy=false >(</mo><mi>S</mi><mo stretchy=false >)</mo><mtext> </mtext><mi mathvariant=normal >.</mi></mrow><annotation encoding="application/x-tex"> \min_{S\succeq 0} l(\Sigma, S) + \lambda \cdot h(S)\,. </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.58951em;vertical-align:-0.83951em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.66786em;"><span style="top:-2.355669em;margin-left:0em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span><span class="mrel mtight">⪰</span><span class="mord mtight">0</span></span></span></span><span style="top:-3em;"><span class=pstrut  style="height:3em;"></span><span><span class=mop >min</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.83951em;"><span></span></span></span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class=mopen >(</span><span class=mord >Σ</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">λ</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >⋅</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">h</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord >.</span></span></span></span></span> <p>We restrict ourselves to searching in the <a href="https://en.wikipedia.org/wiki/Definiteness_of_a_matrix">positive semi-definite</a> &#40;PSD&#41; cone &#40;<span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>⪰</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">S\succeq 0</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8193em;vertical-align:-0.13597em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >⪰</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >0</span></span></span></span>&#41;. Since covariance matrices are PSD, all eigenvalues are non-zero.</p> <p>We will try this out on the <a href="https://archive.ics.uci.edu/ml/datasets/wine">wines dataset</a>, a small dataset containing 13 chemical and physical characteristics of several wines. We will first compute the covariance matrix and subsequently re-estimate this matrix, penalizing the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal">L</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>-, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">L_1</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal">L</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and nuclear norm.</p> <pre><code class="julia hljs">wines = CSV.read(<span class=hljs-string >&quot;wines.csv&quot;</span>)
variables = <span class=hljs-built_in >String</span>.(names(wines))
describe(wines)</code></pre> <table class=data-frame ><thead><tr><th><th>variable<th>mean<th>min<th>median<th>max<th>nunique<th>nmissing<th>eltype<tr><th><th>Symbol<th>Float64<th>Real<th>Float64<th>Real<th>Nothing<th>Int64<th>DataType<p>13 rows × 8 columns</p><tr><th>1<td>Alcohol<td>1.9382<td>1<td>2.0<td>3<td><td>0<td>Int64<tr><th>2<td>Malic acid<td>13.0006<td>11.03<td>13.05<td>14.83<td><td>0<td>Float64<tr><th>3<td>Ash<td>2.33635<td>0.74<td>1.865<td>5.8<td><td>0<td>Float64<tr><th>4<td>Alcalinity of ash<td>2.36652<td>1.36<td>2.36<td>3.23<td><td>0<td>Float64<tr><th>5<td>Magnesium<td>19.4949<td>10.6<td>19.5<td>30.0<td><td>0<td>Float64<tr><th>6<td>Total phenols<td>99.7416<td>70<td>98.0<td>162<td><td>0<td>Int64<tr><th>7<td>Flavanoids<td>2.29511<td>0.98<td>2.355<td>3.88<td><td>0<td>Float64<tr><th>8<td>Nonflavanoid phenols<td>2.02927<td>0.34<td>2.135<td>5.08<td><td>0<td>Float64<tr><th>9<td>Proanthocyanins<td>0.361854<td>0.13<td>0.34<td>0.66<td><td>0<td>Float64<tr><th>10<td>Color intensity<td>1.5909<td>0.41<td>1.555<td>3.58<td><td>0<td>Float64<tr><th>11<td>Hue<td>5.05809<td>1.28<td>4.69<td>13.0<td><td>0<td>Float64<tr><th>12<td>OD280/OD315 of diluted wines<td>0.957449<td>0.48<td>0.965<td>1.71<td><td>0<td>Float64<tr><th>13<td>Proline<td>2.61169<td>1.27<td>2.78<td>4.0<td><td>0<td>Float64</table> <p>We use <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant=normal >Σ</mi></mrow><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class=mord >Σ</span></span></span></span> to denote the unbiased estimator of the covariance.</p> <pre><code class="julia hljs"><span class=hljs-comment ># convert DataFrame to Matrix</span>
X = convert(<span class=hljs-built_in >Matrix</span>, wines)
Σ = cov(X)</code></pre> <pre><code class="julia hljs"><span class=hljs-number >13</span>×<span class=hljs-number >13</span> <span class=hljs-built_in >Array</span>{<span class=hljs-built_in >Float64</span>,<span class=hljs-number >2</span>}:
      <span class=hljs-number >0.600679</span>   -<span class=hljs-number >0.206515</span>    <span class=hljs-number >0.379039</span>   …  -<span class=hljs-number >0.109368</span>    -<span class=hljs-number >0.433737</span>
     -<span class=hljs-number >0.206515</span>    <span class=hljs-number >0.659062</span>    <span class=hljs-number >0.0856113</span>     -<span class=hljs-number >0.0133134</span>    <span class=hljs-number >0.0416978</span>
      <span class=hljs-number >0.379039</span>    <span class=hljs-number >0.0856113</span>   <span class=hljs-number >1.24802</span>       -<span class=hljs-number >0.143326</span>    -<span class=hljs-number >0.292447</span>
     -<span class=hljs-number >0.0105554</span>   <span class=hljs-number >0.0471152</span>   <span class=hljs-number >0.050277</span>      -<span class=hljs-number >0.00468215</span>   <span class=hljs-number >0.000761836</span>
      <span class=hljs-number >1.34036</span>    -<span class=hljs-number >0.841093</span>    <span class=hljs-number >1.07633</span>       -<span class=hljs-number >0.209118</span>    -<span class=hljs-number >0.656234</span>
     -<span class=hljs-number >2.3155</span>      <span class=hljs-number >3.13988</span>    -<span class=hljs-number >0.87078</span>    …   <span class=hljs-number >0.180851</span>     <span class=hljs-number >0.669308</span>
     -<span class=hljs-number >0.348835</span>    <span class=hljs-number >0.146887</span>   -<span class=hljs-number >0.234338</span>       <span class=hljs-number >0.0620389</span>    <span class=hljs-number >0.311021</span>
     -<span class=hljs-number >0.656091</span>    <span class=hljs-number >0.192033</span>   -<span class=hljs-number >0.45863</span>        <span class=hljs-number >0.124082</span>     <span class=hljs-number >0.558262</span>
      <span class=hljs-number >0.0471774</span>  -<span class=hljs-number >0.0157543</span>   <span class=hljs-number >0.0407334</span>     -<span class=hljs-number >0.00747118</span>  -<span class=hljs-number >0.0444692</span>
     -<span class=hljs-number >0.221413</span>    <span class=hljs-number >0.0635175</span>  -<span class=hljs-number >0.141147</span>       <span class=hljs-number >0.0386646</span>    <span class=hljs-number >0.210933</span>
      <span class=hljs-number >0.477339</span>    <span class=hljs-number >1.02828</span>     <span class=hljs-number >0.644838</span>   …  -<span class=hljs-number >0.276506</span>    -<span class=hljs-number >0.705813</span>
     -<span class=hljs-number >0.109368</span>   -<span class=hljs-number >0.0133134</span>  -<span class=hljs-number >0.143326</span>       <span class=hljs-number >0.052245</span>     <span class=hljs-number >0.0917662</span>
     -<span class=hljs-number >0.433737</span>    <span class=hljs-number >0.0416978</span>  -<span class=hljs-number >0.292447</span>       <span class=hljs-number >0.0917662</span>    <span class=hljs-number >0.504086</span></code></pre> <p>We will use a <a href="https://michielstock.github.io/ConvexSummary/">simple gradient descent</a> to solve the ERMP. During the gradient updates, it is possible that <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> is no longer positive semi-definite. For this reason, we will have to project back in the positive semi-definite cone in every step. This can be done by setting negative eigenvalues to zero.</p> <pre><code class="julia hljs"><span class=hljs-keyword >function</span> projectSPDcone!(S)
    vals, vectors = eigen(S)
    vals[vals .&lt; <span class=hljs-number >0.0</span>] .= <span class=hljs-number >0.0</span>
    S .= vectors * Diagonal(vals) * vectors&#x27;
    <span class=hljs-keyword >return</span> S
<span class=hljs-keyword >end</span></code></pre> <p>Similarly, we can use soft-thresholding to set very small values to zero. This is an easy way to make sparse solutions possible.</p> <pre><code class="julia hljs"><span class=hljs-keyword >function</span> softthreshold!(X, tol::<span class=hljs-built_in >Real</span>=<span class=hljs-number >1e-4</span>)
    X[abs.(X) .&lt; tol] .= <span class=hljs-number >0.0</span>
<span class=hljs-keyword >end</span></code></pre> <p>We also need the gradient of loss and regularization functions. These can be computed using automatic differentiation methods, but since the functions are so simple, let&#39;s provide them explicitly:</p> <pre><code class="julia hljs">∇ls(Y, X) = <span class=hljs-number >2</span>(X .- Y)</code></pre>
<pre><code class="julia hljs">∇L₂(X) = <span class=hljs-number >2</span>X
∇L₁(X) = sign.(X)
∇nucl(S) = sign.(Diagonal(S))</code></pre>
<p>Note that here the nuclear regularization is directly on the matrix, since it is already symmetric and PSD.</p>
<p>Putting this all together, we have obtain a general gradient descent function to approximate PSD matrices.</p>
<pre><code class="julia hljs"><span class=hljs-keyword >function</span> PSDapprox(Σ::<span class=hljs-built_in >AbstractArray</span>, ∇norm::<span class=hljs-built_in >Function</span>, ∇loss=∇ls;
                λ=<span class=hljs-number >1.0</span>, stepsize=<span class=hljs-number >1e-3</span>, maxitter=<span class=hljs-number >20_000</span>, tol=<span class=hljs-number >1e-4</span>)
    S = copy(Σ)
    ΔS = similar(S)
    <span class=hljs-keyword >for</span> i <span class=hljs-keyword >in</span> <span class=hljs-number >1</span>:maxitter
        <span class=hljs-comment ># compute gradient of loss + norm</span>
        ΔS .= ∇ls(Σ, S) + λ * ∇norm(S)
        <span class=hljs-comment ># stop if the gradient is small</span>
        <span class=hljs-keyword >if</span> norm(ΔS) &lt; tol
            <span class=hljs-keyword >break</span>
        <span class=hljs-keyword >end</span>
        S -= stepsize * ΔS
        <span class=hljs-comment ># project back into the SPD cone</span>
        S .= projectSPDcone!(S)
        <span class=hljs-comment ># soft thresholding</span>
        softthreshold!(S, tol)
    <span class=hljs-keyword >end</span>
    S
<span class=hljs-keyword >end</span></code></pre>
<pre><code class="julia hljs">PSDapprox (generic <span class=hljs-keyword >function</span> with <span class=hljs-number >2</span> methods)</code></pre>
<p>Let us try for the different regularizers:</p>
<pre><code class="julia hljs">SL₂ = PSDapprox(Σ, ∇L₂, λ=<span class=hljs-number >2e-1</span>)</code></pre>
<pre><code class="julia hljs"><span class=hljs-number >13</span>×<span class=hljs-number >13</span> <span class=hljs-built_in >Array</span>{<span class=hljs-built_in >Float64</span>,<span class=hljs-number >2</span>}:
      <span class=hljs-number >0.500566</span>    -<span class=hljs-number >0.172096</span>    <span class=hljs-number >0.315866</span>   …  -<span class=hljs-number >0.0911396</span>   -<span class=hljs-number >0.361448</span>
     -<span class=hljs-number >0.172096</span>     <span class=hljs-number >0.549219</span>    <span class=hljs-number >0.0713428</span>     -<span class=hljs-number >0.0110945</span>    <span class=hljs-number >0.0347482</span>
      <span class=hljs-number >0.315866</span>     <span class=hljs-number >0.0713428</span>   <span class=hljs-number >1.04001</span>       -<span class=hljs-number >0.119438</span>    -<span class=hljs-number >0.243706</span>
     -<span class=hljs-number >0.00879621</span>   <span class=hljs-number >0.0392626</span>   <span class=hljs-number >0.0418975</span>     -<span class=hljs-number >0.0039018</span>    <span class=hljs-number >0.000634863</span>
      <span class=hljs-number >1.11697</span>     -<span class=hljs-number >0.700911</span>    <span class=hljs-number >0.896943</span>      -<span class=hljs-number >0.174265</span>    -<span class=hljs-number >0.546862</span>
     -<span class=hljs-number >1.92958</span>      <span class=hljs-number >2.61657</span>    -<span class=hljs-number >0.72565</span>    …   <span class=hljs-number >0.150709</span>     <span class=hljs-number >0.557757</span>
     -<span class=hljs-number >0.290696</span>     <span class=hljs-number >0.122406</span>   -<span class=hljs-number >0.195281</span>       <span class=hljs-number >0.0516991</span>    <span class=hljs-number >0.259184</span>
     -<span class=hljs-number >0.546742</span>     <span class=hljs-number >0.160028</span>   -<span class=hljs-number >0.382192</span>       <span class=hljs-number >0.103402</span>     <span class=hljs-number >0.465219</span>
      <span class=hljs-number >0.0393145</span>   -<span class=hljs-number >0.0131286</span>   <span class=hljs-number >0.0339445</span>     -<span class=hljs-number >0.00622598</span>  -<span class=hljs-number >0.0370577</span>
     -<span class=hljs-number >0.184511</span>     <span class=hljs-number >0.0529313</span>  -<span class=hljs-number >0.117623</span>       <span class=hljs-number >0.0322205</span>    <span class=hljs-number >0.175777</span>
      <span class=hljs-number >0.397783</span>     <span class=hljs-number >0.856902</span>    <span class=hljs-number >0.537365</span>   …  -<span class=hljs-number >0.230422</span>    -<span class=hljs-number >0.588177</span>
     -<span class=hljs-number >0.0911396</span>   -<span class=hljs-number >0.0110945</span>  -<span class=hljs-number >0.119438</span>       <span class=hljs-number >0.0435375</span>    <span class=hljs-number >0.0764719</span>
     -<span class=hljs-number >0.361448</span>     <span class=hljs-number >0.0347482</span>  -<span class=hljs-number >0.243706</span>       <span class=hljs-number >0.0764719</span>    <span class=hljs-number >0.420072</span></code></pre>
<pre><code class="julia hljs">SL₁ = PSDapprox(Σ, ∇L₁, λ=<span class=hljs-number >2e-1</span>)</code></pre>
<pre><code class="julia hljs"><span class=hljs-number >13</span>×<span class=hljs-number >13</span> <span class=hljs-built_in >Array</span>{<span class=hljs-built_in >Float64</span>,<span class=hljs-number >2</span>}:
      <span class=hljs-number >0.502745</span>   -<span class=hljs-number >0.105621</span>      <span class=hljs-number >0.279187</span>     …  -<span class=hljs-number >0.0208615</span>    -<span class=hljs-number >0.335675</span>
     -<span class=hljs-number >0.105621</span>    <span class=hljs-number >0.55945</span>       <span class=hljs-number >0.000142351</span>      <span class=hljs-number >0.0</span>           <span class=hljs-number >0.0</span>
      <span class=hljs-number >0.279187</span>    <span class=hljs-number >0.000142351</span>   <span class=hljs-number >1.14803</span>         -<span class=hljs-number >0.0441496</span>    -<span class=hljs-number >0.192586</span>
      <span class=hljs-number >0.0</span>         <span class=hljs-number >0.0</span>           <span class=hljs-number >0.0</span>             -<span class=hljs-number >0.000107562</span>   <span class=hljs-number >0.0</span>
      <span class=hljs-number >1.23978</span>    -<span class=hljs-number >0.741346</span>      <span class=hljs-number >0.97629</span>         -<span class=hljs-number >0.10587</span>      -<span class=hljs-number >0.555687</span>
     -<span class=hljs-number >2.2155</span>      <span class=hljs-number >3.03988</span>      -<span class=hljs-number >0.77078</span>      …   <span class=hljs-number >0.0808711</span>     <span class=hljs-number >0.569311</span>
     -<span class=hljs-number >0.249459</span>    <span class=hljs-number >0.0466174</span>    -<span class=hljs-number >0.134382</span>         <span class=hljs-number >0.0</span>           <span class=hljs-number >0.211606</span>
     -<span class=hljs-number >0.554226</span>    <span class=hljs-number >0.0928404</span>    -<span class=hljs-number >0.358497</span>         <span class=hljs-number >0.0137052</span>     <span class=hljs-number >0.456512</span>
      <span class=hljs-number >0.0</span>         <span class=hljs-number >0.0</span>           <span class=hljs-number >0.0</span>             -<span class=hljs-number >0.000149592</span>   <span class=hljs-number >0.0</span>
     -<span class=hljs-number >0.121912</span>    <span class=hljs-number >0.0</span>          -<span class=hljs-number >0.0411828</span>        <span class=hljs-number >0.0</span>           <span class=hljs-number >0.111401</span>
      <span class=hljs-number >0.376425</span>    <span class=hljs-number >0.927887</span>      <span class=hljs-number >0.544773</span>     …  -<span class=hljs-number >0.171415</span>     -<span class=hljs-number >0.604954</span>
     -<span class=hljs-number >0.0208615</span>   <span class=hljs-number >0.0</span>          -<span class=hljs-number >0.0441496</span>        <span class=hljs-number >0.0162355</span>     <span class=hljs-number >0.00255751</span>
     -<span class=hljs-number >0.335675</span>    <span class=hljs-number >0.0</span>          -<span class=hljs-number >0.192586</span>         <span class=hljs-number >0.00255751</span>    <span class=hljs-number >0.405906</span></code></pre>
<pre><code class="julia hljs">Snucl = PSDapprox(Σ, ∇nucl, λ=<span class=hljs-number >2e-1</span>)</code></pre>
<pre><code class="julia hljs"><span class=hljs-number >13</span>×<span class=hljs-number >13</span> <span class=hljs-built_in >Array</span>{<span class=hljs-built_in >Float64</span>,<span class=hljs-number >2</span>}:
      <span class=hljs-number >0.523474</span>   -<span class=hljs-number >0.2018</span>      <span class=hljs-number >0.378216</span>   …  -<span class=hljs-number >0.102672</span>    -<span class=hljs-number >0.425452</span>
     -<span class=hljs-number >0.2018</span>      <span class=hljs-number >0.560289</span>    <span class=hljs-number >0.0853282</span>     -<span class=hljs-number >0.0146486</span>    <span class=hljs-number >0.0434516</span>
      <span class=hljs-number >0.378216</span>    <span class=hljs-number >0.0853282</span>   <span class=hljs-number >1.14846</span>       -<span class=hljs-number >0.138243</span>    -<span class=hljs-number >0.292814</span>
      <span class=hljs-number >0.0</span>         <span class=hljs-number >0.0474372</span>   <span class=hljs-number >0.0479655</span>     -<span class=hljs-number >0.00677665</span>   <span class=hljs-number >0.00514546</span>
      <span class=hljs-number >1.33877</span>    -<span class=hljs-number >0.841296</span>    <span class=hljs-number >1.07649</span>       -<span class=hljs-number >0.209159</span>    -<span class=hljs-number >0.656809</span>
     -<span class=hljs-number >2.31547</span>     <span class=hljs-number >3.1399</span>     -<span class=hljs-number >0.870777</span>   …   <span class=hljs-number >0.180832</span>     <span class=hljs-number >0.669327</span>
     -<span class=hljs-number >0.360782</span>    <span class=hljs-number >0.143824</span>   -<span class=hljs-number >0.234054</span>       <span class=hljs-number >0.0621105</span>    <span class=hljs-number >0.307935</span>
     -<span class=hljs-number >0.642777</span>    <span class=hljs-number >0.195738</span>   -<span class=hljs-number >0.459109</span>       <span class=hljs-number >0.121481</span>     <span class=hljs-number >0.562478</span>
      <span class=hljs-number >0.0496407</span>  -<span class=hljs-number >0.0149893</span>   <span class=hljs-number >0.0401001</span>     -<span class=hljs-number >0.00982623</span>  -<span class=hljs-number >0.0395298</span>
     -<span class=hljs-number >0.223001</span>    <span class=hljs-number >0.062717</span>   -<span class=hljs-number >0.141305</span>       <span class=hljs-number >0.0383765</span>    <span class=hljs-number >0.21024</span>
      <span class=hljs-number >0.476298</span>    <span class=hljs-number >1.02801</span>     <span class=hljs-number >0.645162</span>   …  -<span class=hljs-number >0.273265</span>    -<span class=hljs-number >0.706216</span>
     -<span class=hljs-number >0.102672</span>   -<span class=hljs-number >0.0146486</span>  -<span class=hljs-number >0.138243</span>       <span class=hljs-number >0.0302173</span>    <span class=hljs-number >0.0936902</span>
     -<span class=hljs-number >0.425452</span>    <span class=hljs-number >0.0434516</span>  -<span class=hljs-number >0.292814</span>       <span class=hljs-number >0.0936902</span>    <span class=hljs-number >0.407482</span></code></pre>
<p>If these matrices are compared with the original matrix <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant=normal >Σ</mi></mrow><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class=mord >Σ</span></span></span></span>, you notice that the values have been shrunken by the regularization: we we sacrifice unbiasedness for a large drop in variance&#33; As promised, the coviance matrix obtained by using <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">L_1</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal">L</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> regularization is quite sparse.</p>
<pre><code class="julia hljs">sparsity SL₂: <span class=hljs-number >0.0</span>
    sparsity SL₁: <span class=hljs-number >0.2603550295857988</span>
    sparsity Snucl: <span class=hljs-number >0.011834319526627219</span></code></pre>
<p>A look at the spectrum of all matrices shows that the nuclear norm results in low-rank matrices.</p>
<p><img src="/images/2019_nuclear/spectrum.png" alt="Comparison of the spectra of the different covariance matrices." /></p>
<p>Checking the rank explicitly:</p>
<pre><code class="julia hljs">rank Σ: <span class=hljs-number >13</span>
    rank SL₂: <span class=hljs-number >13</span>
    rank SL₁: <span class=hljs-number >12</span>
    rank Snucl: <span class=hljs-number >8</span></code></pre>
<p>As claimed.</p>
<h2 id=conclusion ><a href="#conclusion" class=header-anchor >Conclusion</a></h2>
<p>Many machine learning problems can be posed as trying to recover a matrix &#40;e.g. edge prediction in a network, collaborative filtering, image inpainting...&#41;. Emperical risk minimization is a general framework to think about such problems, where the regualarization penalty can be used to impose some structure on the learned matrix.</p>
<p><strong>Footnotes</strong></p>
<p><table class=fndef  id="fndef:UV">
    <tr>
        <td class=fndef-backref ><a href="#fnref:UV">[1]</a>
        <td class=fndef-content >You might wonder why not simply reformulate the problem by substituting <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> by <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi><msup><mi>V</mi><mo>⊺</mo></msup></mrow><annotation encoding="application/x-tex">UV^\intercal</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class=mord ><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin amsrm mtight">⊺</span></span></span></span></span></span></span></span></span></span></span> and minimize the objective w.r.t. <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi></mrow><annotation encoding="application/x-tex">U</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span></span></span></span> and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span>. In this case, the problem is no longer convex and has no longer an unique solution &#40;swapping any corresponding of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi></mrow><annotation encoding="application/x-tex">U</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span></span></span></span> and the corresponding ones in <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span> yields the same objective value&#41;. The optimization problem will no longer have a single minimum is is thus harder to solve.
    
</table>
 <table class=fndef  id="fndef:kernel">
    <tr>
        <td class=fndef-backref ><a href="#fnref:kernel">[2]</a>
        <td class=fndef-content >A related problem would be kernel learning, where the goal is to find a good <a href="https://en.wikipedia.org/wiki/Kernel_method">kernel</a> matrix describing the data.
    
</table>
</p>
<div class=page-foot >
  <div class=copyright >
    &copy; Michiel Stock. Last modified: June 05, 2025. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
  </div>
</div>
</div>
        </div> 
    </div>